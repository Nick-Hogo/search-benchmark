# 模块 04：报告生成

## 目录

- [输入数据](#输入数据)
- [执行清单](#执行清单)
  - [步骤 1：读取测试数据](#步骤-1读取测试数据)
  - [步骤 2：计算统计数据](#步骤-2计算统计数据)
  - [步骤 3：生成单工具报告](#步骤-3生成单工具报告)
  - [步骤 4：生成对比报告](#步骤-4生成对比报告)
  - [步骤 5：展示结果摘要](#步骤-5展示结果摘要)
- [报告模板](#报告模板)
  - [单工具详细报告模板](#单工具详细报告模板)
  - [多工具对比报告模板](#多工具对比报告模板)

---

## 输入数据

从阶段二和阶段三获取的数据：

```
输入来源：
  - 日志文件：{session_dir}/_test_log.jsonl
  - 答卷文件：{session_dir}/answers/{tool_id}.md
  - 分析文件：{session_dir}/analysis/{tool_id}_analysis.md

包含信息：
  - 所有测试结果的JSON数据
  - 所有答案和搜索结果
  - 所有分析报告
```

---

## 执行清单

按照以下步骤逐项完成报告生成任务。**每完成一步，在思考过程中标记为已完成**。

### 步骤 1：读取测试数据

- [ ] 读取日志文件
  ```bash
  Read: {session_dir}/_test_log.jsonl
  ```

- [ ] 解析每行JSON数据
  ```
  每行是一个测试结果的JSON对象
  按工具ID分组存储
  ```

- [ ] 按工具分组
  ```javascript
  results_by_tool = {
    "grok-search": [...],
    "builtin-websearch": [...]
  }
  ```

- [ ] 可选：读取答卷和分析文件
  ```
  方式一：直接从日志文件获取所有数据（推荐，更快）
  方式二：从答卷和分析文件中读取详细信息（更完整）

  根据需要选择合适的方式
  ```

---

### 步骤 2：计算统计数据

对每个工具的测试结果进行统计：

- [ ] 计算维度得分
  ```
  按测试类别（时效性、准确度等）汇总得分

  示例：
    时效性总分 = T1得分 + T2得分 + T3得分
    准确度总分 = A1得分 + A2得分 + A3得分
    ...
  ```

- [ ] 计算性能指标
  ```
  - 平均耗时 = 总耗时 / 测试数量
  - 最快响应 = min(所有耗时)
  - 最慢响应 = max(所有耗时)
  - 成功率 = 成功数 / 总测试数
  ```

- [ ] 识别最佳/最差用例
  ```
  - 找出得分最高的测试用例
  - 找出得分最低的测试用例
  - 找出响应最快的测试用例
  - 找出响应最慢的测试用例
  ```

- [ ] 计算对比数据（如果有多个工具）
  ```
  - 各工具在各维度的排名
  - 各工具的综合得分排名
  - 各工具的性能对比
  ```

---

### 步骤 3：生成单工具报告

对每个测试过的工具生成独立报告：

- [ ] 准备报告数据
  ```
  从步骤2的统计数据中提取该工具的所有信息
  ```

- [ ] 按照模板填充报告内容
  ```
  参考"单工具详细报告模板"部分
  填充所有占位符{...}
  ```

- [ ] 写入报告文件
  ```bash
  Write: {session_dir}/{tool_id}_detailed.md

  文件内容：按模板生成的完整报告
  ```

- [ ] 显示进度
  ```
  ✅ 已生成 {tool_name} 详细报告
  ```

---

### 步骤 4：生成对比报告

仅在测试了多个工具时执行：

- [ ] 检查工具数量
  ```
  如果 tools_count <= 1:
    跳过此步骤，不生成对比报告

  如果 tools_count > 1:
    继续执行对比报告生成
  ```

- [ ] 准备对比数据
  ```
  - 各工具的维度得分对比
  - 各工具的逐题对比
  - 各工具的性能对比
  - 综合排名
  ```

- [ ] 按照模板填充报告内容
  ```
  参考"多工具对比报告模板"部分
  填充所有占位符{...}
  ```

- [ ] 生成推荐建议
  ```
  基于测试结果，给出不同场景下的工具推荐：
    - 需要高时效性时，推荐哪个工具
    - 需要高准确度时，推荐哪个工具
    - 追求平衡性能时，推荐哪个工具
  ```

- [ ] 写入对比报告文件
  ```bash
  Write: {session_dir}/summary_comparison.md

  文件内容：按模板生成的完整对比报告
  ```

- [ ] 显示进度
  ```
  ✅ 已生成多工具对比报告
  ```

---

### 步骤 5：展示结果摘要

- [ ] 计算总体统计
  ```
  - 总测试数
  - 总耗时
  - 平均耗时
  - 测试工具数量
  - 测试用例数量
  ```

- [ ] 准备文件清单
  ```
  列出所有生成的报告文件：
    - summary_comparison.md (如果有)
    - {tool1}_detailed.md
    - {tool2}_detailed.md (如果有)
    - answers/*.md
    - analysis/*_analysis.md
    - _test_log.jsonl
  ```

- [ ] 向用户展示结果摘要
  ```
  测试完成！

  📊 测试概要：
  - 测试工具：{count}个 ({工具名称列表})
  - 测试用例：{count}个
  - 总耗时：{elapsed}秒
  - 平均耗时：{avg}秒/题

  📁 报告保存位置：
  {完整绝对路径}/{session_dir}/

  📄 生成文件：
    ├── summary_comparison.md     # 多工具对比报告（推荐先看）
    ├── {tool1}_detailed.md       # 工具1详细报告
    ├── {tool2}_detailed.md       # 工具2详细报告
    ├── answers/                  # 原始答卷
    │   ├── {tool1}.md
    │   └── {tool2}.md
    ├── analysis/                 # 详细分析
    │   ├── {tool1}_analysis.md
    │   └── {tool2}_analysis.md
    └── _test_log.jsonl           # 原始测试数据

  🔍 快速查看：
  请打开 summary_comparison.md 查看对比结果

  🏆 快速结论（如果有对比）：
  1位 {tool_1}: {score}/120 ({pct}%)
  2位 {tool_2}: {score}/120 ({pct}%)
  ```

---

## 报告模板

### 单工具详细报告模板

```markdown
# {Tool Name} 详细测试报告

**生成时间**: {timestamp}
**测试用例数**: {total_cases}
**总耗时**: {total_elapsed}秒

---

## 总体表现

| 维度 | 得分 | 满分 | 得分率 |
|------|------|------|--------|
| 时效性 | {score}/30 | 30 | {percentage}% |
| 准确度 | {score}/30 | 30 | {percentage}% |
| 抗幻觉 | {score}/30 | 30 | {percentage}% |
| 可核查性 | {score}/20 | 20 | {percentage}% |
| 效率 | {score}/10 | 10 | {percentage}% |
| **总分** | **{total}/120** | 120 | **{percentage}%** |

**总体评价**：
{根据得分率生成评语：
  >= 90%: 优秀！各项指标均表现出色，建议作为首选工具。
  >= 80%: 良好。整体表现可靠，少数项目有提升空间。
  >= 70%: 中等。基本满足需求，但在某些维度需要改进。
  < 70%: 待改进。建议优化搜索策略和结果质量控制。
}

---

## 逐题分析

{对每个测试用例，按以下格式展示：}

### [{test_case_id}] {test_case_name}

**分类**: {category}

**问题**:
```
{test_case.prompt}
```

**答案**:
```
{answer}
```

**评分**: {score}/{max_score} ({percentage}%)

**详细评分**:
| 判定标准 | 得分 | 满分 | 理由 |
|----------|------|------|------|
| {criterion_1} | {score} | {max} | {reason} |
| {criterion_2} | {score} | {max} | {reason} |

**耗时**: {elapsed_time}秒

**原始搜索结果摘要** (前3条):
1. [{title}]({url}) - {snippet}
2. ...
3. ...

---

{重复以上格式展示所有测试用例}

---

## 优势与不足

### 优势
{基于得分自动生成，例如：}
- 时效性控制优秀（90%得分率）
- 抗幻觉能力强（正确拒绝所有虚假信息）

### 需要改进
{基于失分项生成，例如：}
- 可核查性有待提升（部分答案缺少独立引用）
- 效率可以优化（平均响应时间 5.2秒）

---

## 性能指标

- **平均响应时间**: {avg_elapsed}秒
- **最快响应**: {min_elapsed}秒 ({test_case_id})
- **最慢响应**: {max_elapsed}秒 ({test_case_id})
- **成功率**: {success_count}/{total_count} ({percentage}%)
```

---

### 多工具对比报告模板

```markdown
# 搜索工具对比测试报告

**生成时间**: {timestamp}
**测试工具数**: {tools_count}个
**测试用例数**: {total_cases}个
**总耗时**: {total_elapsed}秒

---

## 综合排名

| 排名 | 工具 | 总分 | 时效性 | 准确度 | 抗幻觉 | 可核查性 | 效率 | 平均耗时 |
|------|------|------|--------|--------|--------|----------|------|----------|
| 1 | {tool_1} | {score}/120 ({pct}%) | {s1}/30 | {s2}/30 | {s3}/30 | {s4}/20 | {s5}/10 | {avg}s |
| 2 | {tool_2} | {score}/120 ({pct}%) | {s1}/30 | {s2}/30 | {s3}/30 | {s4}/20 | {s5}/10 | {avg}s |

---

## 维度对比分析

### 时效性对比

| 工具 | 得分 | T1 | T2 | T3 |
|------|------|----|----|-----|
| {tool_1} | {total}/30 | {t1}/10 | {t2}/10 | {t3}/10 |
| {tool_2} | {total}/30 | {t1}/10 | {t2}/10 | {t3}/10 |

**分析**:
- 最佳: {winner_tool} ({score}/30, {pct}%)
- 关键差异: {描述主要差异，如"Grok Search在硬时间窗口测试中表现更好"}

### 准确度对比

{同上格式}

### 抗幻觉对比

{同上格式}

### 可核查性对比

{同上格式}

### 效率对比

| 工具 | 平均耗时 | 最快 | 最慢 | 得分 |
|------|----------|------|------|------|
| {tool_1} | {avg}s | {min}s | {max}s | {score}/10 |
| {tool_2} | {avg}s | {min}s | {max}s | {score}/10 |

---

## 逐题对比

{对每个测试用例，展示不同工具的表现对比：}

### [{test_case_id}] {test_case_name}

| 工具 | 得分 | 耗时 | 关键差异 |
|------|------|------|----------|
| {tool_1} | {score}/10 | {time}s | {简述答案特点} |
| {tool_2} | {score}/10 | {time}s | {简述答案特点} |

**最佳表现**: {winner_tool} (+{diff}分)
**原因**: {分析为什么这个工具表现更好}

---

{重复展示所有测试用例}

---

## 关键发现

### 最佳表现

1. **时效性最强**: {tool} (T1测试得分 {score}/10)
   - 理由: {原因}

2. **准确度最高**: {tool} (A1测试得分 {score}/10)
   - 理由: {原因}

3. **抗幻觉最佳**: {tool} (H1测试拒绝率 100%)
   - 理由: {原因}

### 性能对比

- **响应最快**: {tool} (平均 {avg}秒)
- **质量最优**: {tool} (综合得分 {score}/120)

### 推荐选择

**场景 1：需要高时效性**
- 推荐：{tool}
- 理由：{原因}

**场景 2：需要高准确度**
- 推荐：{tool}
- 理由：{原因}

**场景 3：平衡性能**
- 推荐：{tool}
- 理由：综合得分最高（{score}/120）

---

## 详细报告链接

{为每个工具生成链接：}
- [{tool_1_name} 详细报告](./{tool_1_id}_detailed.md)
- [{tool_2_name} 详细报告](./{tool_2_id}_detailed.md)

---

## 原始数据

完整测试数据：[_test_log.jsonl](./_test_log.jsonl)
```

---

## 自动化评语生成

根据得分自动生成评语：

```javascript
function generateComment(percentage) {
  if (percentage >= 90) {
    return "优秀！各项指标均表现出色，建议作为首选工具。";
  } else if (percentage >= 80) {
    return "良好。整体表现可靠，少数项目有提升空间。";
  } else if (percentage >= 70) {
    return "中等。基本满足需求，但在某些维度需要改进。";
  } else {
    return "待改进。建议优化搜索策略和结果质量控制。";
  }
}
```
