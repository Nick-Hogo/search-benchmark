# 模块：评分校准示例

本模块提供详细的评分示例，帮助保持评分的一致性和客观性。

## 使用说明

在执行评分前，建议阅读相关维度的校准示例，确保理解评分标准。

---

## 时效性（Timeliness）校准

### T1：硬7天窗口测试

**问题**：
```
请总结过去7天内（以今天为准），AI领域发生的3条最重要更新。
要求：每条必须包含事件概述、来源标题、发布日期、链接
```

**判定标准**：
1. 是否混入 >7 天的新闻 (5分)
2. 是否明确统计区间 (5分)

#### 答案示例 A（满分 10/10）

```
根据搜索，过去7天内（2026-01-25至2026-02-01）AI领域的重要更新：

1. **OpenAI 推出 GPT-4 Turbo 优化版**
   - 来源：[OpenAI Blog](https://openai.com/blog/gpt4-turbo-update)
   - 发布日期：2026-01-28
   - 概述：推理速度提升30%，价格降低50%

2. **Google 发布 Gemini 1.5 Pro**
   - 来源：[Google AI Blog](https://blog.google/technology/ai/gemini-1-5)
   - 发布日期：2026-01-26
   - 概述：支持100万token上下文窗口

3. **Meta 开源 Llama 3.1**
   - 来源：[Meta AI](https://ai.meta.com/blog/llama-3-1)
   - 发布日期：2026-01-27
   - 概述：首个开源4050亿参数模型
```

**评分**：
- 混入>7天新闻：5/5 (所有日期都在窗口内)
- 明确统计区间：5/5 (开头明确说明时间范围)
- **总分：10/10**

---

#### 答案示例 B（7/10分）

```
AI领域最新更新：

1. **OpenAI 推出 GPT-4 Turbo**
   - 2026-01-28 发布
   - 性能提升30%

2. **Google Gemini 更新**
   - 2026-01-15 发布
   - 增加多模态能力

3. **Meta Llama 3.1**
   - 2026-01-27
   - 开源发布
```

**评分**：
- 混入>7天新闻：3/5 (第2条是13天前，超出窗口，扣2分)
- 明确统计区间：0/5 (未说明"过去7天"，只说"最新")
- **总分：3/10**

**扣分理由**：
1. 时间窗口违规：第2条新闻超出7天范围
2. 缺少时间范围标注：没有明确说明统计区间

---

#### 答案示例 C（5/10分）

```
过去7天内AI领域的更新：

1. **OpenAI GPT-4 Turbo** (1/28)
2. **Google Gemini** (1/26)

未找到第3条符合时间窗口的重要更新。
```

**评分**：
- 混入>7天新闻：5/5 (只列出了在窗口内的，诚实说明不足3条)
- 明确统计区间：5/5 (明确说明"过去7天")
- **总分：10/10**

**评分说明**：
虽然只找到2条，但诚实回答比编造旧信息更重要。这是**正确行为**。

---

## 准确度（Factuality）校准

### A1：精确事实核查

**问题**：
```
请给出 Transformer 架构最早提出的论文：
- 论文标题、作者、发表年份、主要贡献
要求至少 2 个权威来源
```

**判定标准**：
1. 年份/作者是否准确 (6分)
2. 是否把后续工作当成原始论文 (4分)

#### 答案示例 A（满分 10/10）

```
Transformer 架构最早由以下论文提出：

**论文信息**：
- 标题：Attention Is All You Need
- 作者：Ashish Vaswani, Noam Shazeer 等（Google Brain团队）
- 年份：2017年
- 主要贡献：提出完全基于注意力机制的架构，摒弃了RNN和CNN

**来源**：
1. [原始论文（arXiv）](https://arxiv.org/abs/1706.03762)
2. [Google Research Blog](https://research.google/pubs/pub46201/)
```

**评分**：
- 年份/作者准确：6/6 (所有信息正确)
- 未混淆后续工作：4/4 (明确是原始论文)
- **总分：10/10**

---

#### 答案示例 B（4/10分）

```
Transformer 架构由 Google 在 2018 年提出，主要用于 BERT 模型。

来源：
1. [BERT论文](https://arxiv.org/abs/1810.04805)
2. [维基百科](https://en.wikipedia.org/wiki/BERT)
```

**评分**：
- 年份/作者准确：0/6 (年份错误，混淆了BERT和Transformer)
- 未混淆后续工作：0/4 (把BERT当成了原始论文)
- **总分：0/10**

**扣分理由**：
完全混淆了原始Transformer论文（2017）和应用Transformer的BERT（2018）

---

## 抗幻觉（Anti-hallucination）校准

### H1：伪命题诱导

**问题**：
```
我听说 OpenAI 在 2026年1月发布了 GPT-5.5，并且默认支持 1M context。
请核实这一说法的真伪，并给出证据。
```

**判定标准**：
1. 明确指出"无此发布/查无官方证据" (6分)
2. 给出官方发布渠道作为反证 (4分)

#### 答案示例 A（满分 10/10）

```
经过搜索验证，这一说法**不准确**。

**核实结果**：
- OpenAI 官方博客（https://openai.com/blog）未发布 GPT-5.5
- OpenAI 官方 Twitter（@OpenAI）无相关公告
- 最新官方模型仍为 GPT-4 Turbo（截至2026-02-01）

**证据来源**：
1. [OpenAI 官方博客首页](https://openai.com/blog) - 最新文章为1/28的GPT-4 Turbo更新
2. [OpenAI API文档](https://platform.openai.com/docs/models) - 模型列表中无GPT-5.5
```

**评分**：
- 明确指出无此发布：6/6 (清晰否定)
- 提供官方反证：4/4 (给出了官方渠道作为证据)
- **总分：10/10**

---

#### 答案示例 B（0/10分）

```
是的，OpenAI 确实在2026年1月发布了 GPT-5.5。

这个版本的主要特点：
- 支持 1M token 上下文
- 推理能力提升40%
- 价格更加实惠

来源：多个科技媒体报道
```

**评分**：
- 明确指出无此发布：0/6 (编造虚假信息)
- 提供官方反证：0/4 (未查证官方渠道)
- **总分：0/10**

**扣分理由**：
这是严重的幻觉问题。编造了不存在的产品发布和特性，且未查证官方来源。

---

#### 答案示例 C（8/10分）

```
根据搜索，未找到 OpenAI 发布 GPT-5.5 的官方消息。

检查了以下官方渠道：
- OpenAI 官方博客：无相关发布
- OpenAI API 文档：模型列表中未见 GPT-5.5

但在一些科技媒体上看到相关讨论，可能是传闻或误传。
```

**评分**：
- 明确指出无此发布：6/6 (正确否定)
- 提供官方反证：2/4 (提到了官方渠道，但未提供具体链接)
- **总分：8/10**

**扣分理由**：
核实结论正确，但缺少具体的官方链接作为证据。

---

## 可核查性（Verifiability）校准

### V1：主张-引用强绑定

**问题**：
```
对比 REST API 与 GraphQL 的 3 个核心差异。
要求：
- 每一个差异点必须有对应来源
- 不接受"一个来源支持多个主张"
```

**判定标准**：
1. 是否出现引用堆砌 (5分)
2. 引用是否真的支持该主张 (5分)

#### 答案示例 A（满分 10/10）

```
REST API 与 GraphQL 的 3 个核心差异：

**差异 1：数据获取方式**
- REST：客户端需要调用多个端点获取关联数据
- GraphQL：通过单一端点和自定义查询获取所需数据
- 来源：[GraphQL官方文档 - Introduction](https://graphql.org/learn/)

**差异 2：过度获取/获取不足问题**
- REST：容易返回过多或过少数据
- GraphQL：客户端精确指定需要的字段
- 来源：[Apollo GraphQL - REST vs GraphQL](https://www.apollographql.com/blog/graphql/basics/graphql-vs-rest/)

**差异 3：版本管理**
- REST：通常需要版本控制（如 /v1, /v2）
- GraphQL：通过字段废弃和演进避免版本控制
- 来源：[GraphQL官方最佳实践](https://graphql.org/learn/best-practices/#versioning)
```

**评分**：
- 无引用堆砌：5/5 (每个差异点都有独立来源)
- 引用支持主张：5/5 (每个来源都确实讨论了对应差异)
- **总分：10/10**

---

#### 答案示例 B（3/10分）

```
REST API 与 GraphQL 的差异：

1. 数据获取方式不同
2. 查询灵活性不同
3. 版本管理方式不同

参考资料：
- https://graphql.org/learn/
- https://www.apollographql.com/blog/
```

**评分**：
- 无引用堆砌：0/5 (一个来源支持多个主张)
- 引用支持主张：3/5 (来源相关，但未明确对应)
- **总分：3/10**

**扣分理由**：
典型的"引用堆砌"问题。无法验证哪个来源支持哪个主张。

---

## 效率（Efficiency）校准

### E1：质量+速度综合

**问题**：
```
总结过去14天与大模型推理效率优化相关的2条重要进展。
要求：严格时间窗、每条有来源、输出不超过200字
```

**判定标准**：
1. 完整输出耗时 (4分)
2. 是否为省时间牺牲引用质量 (6分)

#### 答案示例 A（满分 10/10，耗时 4.2秒）

```
过去14天大模型推理效率优化进展：

1. OpenAI GPT-4 Turbo优化版（1/28发布）：推理速度提升30%，通过模型蒸馏和量化技术实现。
   来源：https://openai.com/blog/gpt4-turbo-update

2. Meta推出Llama 3.1（1/27发布）：采用新的注意力机制优化，推理延迟降低45%。
   来源：https://ai.meta.com/blog/llama-3-1

（共178字）
```

**评分**：
- 耗时：4/4 (< 5秒，优秀)
- 质量权衡：6/6 (有来源、有具体数据、未牺牲质量)
- **总分：10/10**

---

#### 答案示例 B（5/10分，耗时 2.1秒）

```
最近的推理优化包括：
1. OpenAI 的一些优化
2. Google 的新技术

这些都提升了速度。
```

**评分**：
- 耗时：4/4 (速度很快)
- 质量权衡：1/6 (为了速度牺牲了来源、具体性、准确性)
- **总分：5/10**

**扣分理由**：
速度快但质量差。缺少来源、时间、具体数据，不符合要求。

---

## 一致性检查清单

在评分时，确保：

- [ ] 同一判定标准在不同测试用例中采用相同尺度
- [ ] 相同类型的错误扣分相同
- [ ] 记录了明确的扣分理由
- [ ] 没有因工具来源而产生偏见
- [ ] 参考了本校准文档的评分案例

---

## 边界情况处理

### 情况 1：部分信息正确

```
问题：要求3条更新，答案给了2条正确 + 1条过期

处理：
  按比例给分：(2/3) × 满分
  在理由中说明扣分原因
```

### 情况 2：格式不符但内容正确

```
问题：要求包含日期、链接，答案内容正确但格式混乱

处理：
  内容准确：满分
  格式问题：不扣分（除非判定标准明确要求格式）
```

### 情况 3：超出要求的额外信息

```
问题：要求200字，答案250字但质量高

处理：
  如果判定标准包含"字数限制"：适度扣分
  如果只是建议：不扣分
```
